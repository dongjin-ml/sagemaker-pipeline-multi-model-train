{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b8ad79b-8413-41a4-b208-97ae2f5a712f",
   "metadata": {},
   "source": [
    "## <B> Setup for SageMaker pipleline for training multi models </B>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a02c341c-59e9-4816-95ca-5646c6105b30",
   "metadata": {},
   "source": [
    "## AutoReload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "89fc2e2b-3dad-4c1a-b05e-873e5e003c56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e944d3d8-2d36-414b-a6b2-e57865e7d628",
   "metadata": {},
   "source": [
    "## 1. Check execution role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "3560407a-f8dc-401e-9f6c-210a72161b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker import get_execution_role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "8b42a763-286d-4fa6-9e71-b34a899117f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SageMaker Execution Role Name: AmazonSageMaker-ExecutionRole-20221004T162466\n"
     ]
    }
   ],
   "source": [
    "strSageMakerRoleName = get_execution_role().rsplit('/', 1)[-1]\n",
    "print (f\"SageMaker Execution Role Name: {strSageMakerRoleName}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5de593e6-dfe3-4c88-a22d-9ae0e68c8f62",
   "metadata": {},
   "source": [
    "## 2. Set default parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "996d6847-047a-472e-a0ce-77985a6930aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "from utils.ssm import parameter_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "c8a5c892-2162-4589-8131-cad147567032",
   "metadata": {},
   "outputs": [],
   "source": [
    "strRegionName=boto3.Session().region_name\n",
    "pm = parameter_store(strRegionName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "9ad27701-2421-4b93-bfb8-12178a3c7051",
   "metadata": {},
   "outputs": [],
   "source": [
    "strPrefix = \"SM-PIPELINE-MULTI-MODELS-\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "bfd6cbf0-ab0f-44d1-af65-21a901459451",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Store suceess'"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pm.put_params(key=\"PREFIX\", value=strPrefix, overwrite=True)\n",
    "pm.put_params(key=\"\".join([strPrefix, \"REGION\"]), value=strRegionName, overwrite=True)\n",
    "pm.put_params(key=\"\".join([strPrefix, \"DEFAULT-BUCKET\"]), value=sagemaker.Session().default_bucket(), overwrite=True)\n",
    "pm.put_params(key=\"\".join([strPrefix, \"SAGEMAKER-ROLE-ARN\"]), value=get_execution_role(), overwrite=True)\n",
    "pm.put_params(key=\"\".join([strPrefix, \"ACCOUNT-ID\"]), value=boto3.client(\"sts\").get_caller_identity().get(\"Account\"), overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5085c20f-1bdf-4b1c-9039-c341fea4b67b",
   "metadata": {},
   "source": [
    "## 2. Datasets\n",
    "> 가정: 각 모델별 인풋은 모두 다르다. <br>\n",
    "> 모델별 데이터를 s3에 다른 이름으로 저장한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d85488bc-b6ee-4af4-a67f-777de5857719",
   "metadata": {},
   "source": [
    "### 2.1 Create bucket for input datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "cf11f3f1-2471-4627-9bd6-3d2d7c31d48f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.s3 import s3_handler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "aa7fac33-25d3-4b98-ada5-f76c019d95cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a S3 handler with [ap-northeast-2] region.\n"
     ]
    }
   ],
   "source": [
    "s3 = s3_handler(region_name=pm.get_params(key=strPrefix + \"REGION\"))\n",
    "strDataBucketName = f\"{strPrefix.lower()}datasets\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "dc17dab9-8938-4d4d-94f8-179c25d461cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CREATE:[sm-pipeline-multi-models-datasets] Bucket was created successfully\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Store suceess'"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s3.create_bucket(bucket_name=strDataBucketName)\n",
    "pm.put_params(key=\"\".join([strPrefix, \"DATA-BUCKET\"]), value=strDataBucketName, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "d00a5b37-b450-4e30-af6c-bf82206157d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DELETE: [sm-pipeline-multi-models-datasets] Bucket was deleted successfully\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s3.delete_bucket(bucket_name=c) ## delete bucket as well as objects"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b2787bb-09f3-4da8-886f-1b18f2459456",
   "metadata": {},
   "source": [
    "### 2.2. Store datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "966ecad8-535b-491c-a3bb-e492c4eae2dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures\n",
    "import functools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "06429cb0-7869-4700-b9d7-df52c411671a",
   "metadata": {},
   "outputs": [],
   "source": [
    "nModels = 90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "cbefabb3-38ea-4a87-8561-d6cec10665cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def worker(strDataBucketName, args):\n",
    "    nIdx, nSpare= args\n",
    "    print (\"worker\", nIdx, nSpare, strDataBucketName)\n",
    "    s3.copy_object(\n",
    "        source_obj=\"amazon-reviews-pds/tsv/amazon_reviews_us_Electronics_v1_00.tsv.gz\",\n",
    "        target_bucket=strDataBucketName,\n",
    "        target_obj=f\"model-{nIdx+1}/amazon_reviews_us_Electronics_v1_00.tsv.gz\"\n",
    "    )\n",
    "    return f\"job-{nIdx} was completed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "ed307709-edb7-4810-80b2-a93288d10b0a",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "worker 0 1 sm-pipeline-multi-models-datasets\n",
      "worker 1 2 sm-pipeline-multi-models-datasets\n",
      "worker 2 3 sm-pipeline-multi-models-datasets\n",
      "workerworker 4 5 sm-pipeline-multi-models-datasets\n",
      " 3 4 sm-pipeline-multi-models-datasets\n",
      "worker worker 6 7 sm-pipeline-multi-models-datasets\n",
      "5 6 sm-pipeline-multi-models-datasets\n",
      "worker 7 8 sm-pipeline-multi-models-datasets\n",
      "worker 8worker 9 10 sm-pipeline-multi-models-datasets\n",
      " 9 sm-pipeline-multi-models-datasets\n",
      "worker 10 11 sm-pipeline-multi-models-datasets\n",
      "worker 11 12 sm-pipeline-multi-models-datasets\n",
      "worker 12 13 sm-pipeline-multi-models-datasets\n",
      "workerworker 14 15 sm-pipeline-multi-models-datasets\n",
      " 13 14 sm-pipeline-multi-models-datasets\n",
      "worker 15worker  worker16 17 sm-pipeline-multi-models-datasets\n",
      "16  17 18 sm-pipeline-multi-models-datasets\n",
      "sm-pipeline-multi-models-datasetsworker \n",
      "18 worker worker 20 21 sm-pipeline-multi-models-datasetsworker 21 22 sm-pipeline-multi-models-datasets\n",
      "1919\n",
      " sm-pipeline-multi-models-datasets\n",
      "worker 22 23 sm-pipeline-multi-models-datasets\n",
      "worker 23 24 sm-pipeline-multi-models-datasets\n",
      "worker 24 25 sm-pipeline-multi-models-datasets\n",
      "worker 20 sm-pipeline-multi-models-datasets\n",
      "worker 26 27 sm-pipeline-multi-models-datasetsworker 27 28 sm-pipeline-multi-models-datasets\n",
      "\n",
      "worker  2528 29 sm-pipeline-multi-models-datasets\n",
      " 26 sm-pipeline-multi-models-datasets\n",
      "worker 29 30 sm-pipeline-multi-models-datasets\n",
      "worker 30 31 sm-pipeline-multi-models-datasets\n",
      "worker 31 32 sm-pipeline-multi-models-datasets\n",
      "worker 32 33 sm-pipeline-multi-models-datasets\n",
      "worker 33 34 sm-pipeline-multi-models-datasets\n",
      "worker 34 35 sm-pipeline-multi-models-datasets\n",
      "worker 35 36 sm-pipeline-multi-models-datasets\n",
      "worker 36 37 sm-pipeline-multi-models-datasets\n",
      "worker 37 38 sm-pipeline-multi-models-datasets\n",
      "worker 38 39 sm-pipeline-multi-models-datasets\n",
      "worker 39 40 sm-pipeline-multi-models-datasets\n",
      "worker 40 41 sm-pipeline-multi-models-datasets\n",
      "worker 41 42 sm-pipeline-multi-models-datasets\n",
      "worker 42 43 sm-pipeline-multi-models-datasets\n",
      "worker 43 44 sm-pipeline-multi-models-datasets\n",
      "worker 44 45 sm-pipeline-multi-models-datasets\n",
      "worker 45 46 sm-pipeline-multi-models-datasets\n",
      "worker 46 47 sm-pipeline-multi-models-datasets\n",
      "worker 47 48 sm-pipeline-multi-models-datasets\n",
      "worker 48 49 sm-pipeline-multi-models-datasets\n",
      "worker 49 50 sm-pipeline-multi-models-datasets\n",
      "worker 50 51 sm-pipeline-multi-models-datasets\n",
      "worker 51 52 sm-pipeline-multi-models-datasets\n",
      "worker 52 53 sm-pipeline-multi-models-datasets\n",
      "worker 53 54 sm-pipeline-multi-models-datasets\n",
      "worker 54 55 sm-pipeline-multi-models-datasets\n",
      "worker 55 56 sm-pipeline-multi-models-datasets\n",
      "worker 56 57 sm-pipeline-multi-models-datasets\n",
      "worker 57 58 sm-pipeline-multi-models-datasets\n",
      "worker 58 59 sm-pipeline-multi-models-datasets\n",
      "worker 59 60 sm-pipeline-multi-models-datasets\n",
      "worker 60 61 sm-pipeline-multi-models-datasets\n",
      "worker 61 62 sm-pipeline-multi-models-datasets\n",
      "worker 62 63 sm-pipeline-multi-models-datasets\n",
      "worker 63 64 sm-pipeline-multi-models-datasets\n",
      "worker 64 65 sm-pipeline-multi-models-datasets\n",
      "worker 65 66 sm-pipeline-multi-models-datasets\n",
      "worker 66 67 sm-pipeline-multi-models-datasets\n",
      "worker 67 68 sm-pipeline-multi-models-datasets\n",
      "worker 68 69 sm-pipeline-multi-models-datasets\n",
      "worker 69 70 sm-pipeline-multi-models-datasets\n",
      "worker 70 71 sm-pipeline-multi-models-datasets\n",
      "worker 71 72 sm-pipeline-multi-models-datasets\n",
      "worker 72 73 sm-pipeline-multi-models-datasets\n",
      "worker 73 74 sm-pipeline-multi-models-datasets\n",
      "worker 74 75 sm-pipeline-multi-models-datasets\n",
      "worker 75 76 sm-pipeline-multi-models-datasets\n",
      "worker 76 77 sm-pipeline-multi-models-datasets\n",
      "worker 77 78 sm-pipeline-multi-models-datasets\n",
      "worker 78 79 sm-pipeline-multi-models-datasets\n",
      "worker 79 80 sm-pipeline-multi-models-datasets\n",
      "worker 80 81 sm-pipeline-multi-models-datasets\n",
      "worker 81 82 sm-pipeline-multi-models-datasets\n",
      "worker 82 83 sm-pipeline-multi-models-datasets\n",
      "worker 83 84 sm-pipeline-multi-models-datasets\n",
      "worker 84 85 sm-pipeline-multi-models-datasets\n",
      "worker 85 86 sm-pipeline-multi-models-datasets\n",
      "worker 86 87 sm-pipeline-multi-models-datasets\n",
      "worker 87 88 sm-pipeline-multi-models-datasets\n",
      "worker 88 89 sm-pipeline-multi-models-datasets\n",
      "worker 89 90 sm-pipeline-multi-models-datasets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:urllib3.connectionpool:Connection pool is full, discarding connection: sm-pipeline-multi-models-datasets.s3.ap-northeast-2.amazonaws.com. Connection pool size: 10\n",
      "WARNING:urllib3.connectionpool:Connection pool is full, discarding connection: sm-pipeline-multi-models-datasets.s3.ap-northeast-2.amazonaws.com. Connection pool size: 10\n",
      "WARNING:urllib3.connectionpool:Connection pool is full, discarding connection: sm-pipeline-multi-models-datasets.s3.ap-northeast-2.amazonaws.com. Connection pool size: 10\n",
      "WARNING:urllib3.connectionpool:Connection pool is full, discarding connection: sm-pipeline-multi-models-datasets.s3.ap-northeast-2.amazonaws.com. Connection pool size: 10\n",
      "WARNING:urllib3.connectionpool:Connection pool is full, discarding connection: sm-pipeline-multi-models-datasets.s3.ap-northeast-2.amazonaws.com. Connection pool size: 10\n",
      "WARNING:urllib3.connectionpool:Connection pool is full, discarding connection: sm-pipeline-multi-models-datasets.s3.ap-northeast-2.amazonaws.com. Connection pool size: 10\n",
      "WARNING:urllib3.connectionpool:Connection pool is full, discarding connection: sm-pipeline-multi-models-datasets.s3.ap-northeast-2.amazonaws.com. Connection pool size: 10\n",
      "WARNING:urllib3.connectionpool:Connection pool is full, discarding connection: sm-pipeline-multi-models-datasets.s3.ap-northeast-2.amazonaws.com. Connection pool size: 10\n",
      "WARNING:urllib3.connectionpool:Connection pool is full, discarding connection: sm-pipeline-multi-models-datasets.s3.ap-northeast-2.amazonaws.com. Connection pool size: 10\n",
      "WARNING:urllib3.connectionpool:Connection pool is full, discarding connection: sm-pipeline-multi-models-datasets.s3.ap-northeast-2.amazonaws.com. Connection pool size: 10\n",
      "WARNING:urllib3.connectionpool:Connection pool is full, discarding connection: sm-pipeline-multi-models-datasets.s3.ap-northeast-2.amazonaws.com. Connection pool size: 10\n",
      "WARNING:urllib3.connectionpool:Connection pool is full, discarding connection: sm-pipeline-multi-models-datasets.s3.ap-northeast-2.amazonaws.com. Connection pool size: 10\n",
      "WARNING:urllib3.connectionpool:Connection pool is full, discarding connection: sm-pipeline-multi-models-datasets.s3.ap-northeast-2.amazonaws.com. Connection pool size: 10\n",
      "WARNING:urllib3.connectionpool:Connection pool is full, discarding connection: sm-pipeline-multi-models-datasets.s3.ap-northeast-2.amazonaws.com. Connection pool size: 10\n",
      "WARNING:urllib3.connectionpool:Connection pool is full, discarding connection: sm-pipeline-multi-models-datasets.s3.ap-northeast-2.amazonaws.com. Connection pool size: 10\n",
      "WARNING:urllib3.connectionpool:Connection pool is full, discarding connection: sm-pipeline-multi-models-datasets.s3.ap-northeast-2.amazonaws.com. Connection pool size: 10\n",
      "WARNING:urllib3.connectionpool:Connection pool is full, discarding connection: sm-pipeline-multi-models-datasets.s3.ap-northeast-2.amazonaws.com. Connection pool size: 10\n",
      "WARNING:urllib3.connectionpool:Connection pool is full, discarding connection: sm-pipeline-multi-models-datasets.s3.ap-northeast-2.amazonaws.com. Connection pool size: 10\n",
      "WARNING:urllib3.connectionpool:Connection pool is full, discarding connection: sm-pipeline-multi-models-datasets.s3.ap-northeast-2.amazonaws.com. Connection pool size: 10\n",
      "WARNING:urllib3.connectionpool:Connection pool is full, discarding connection: sm-pipeline-multi-models-datasets.s3.ap-northeast-2.amazonaws.com. Connection pool size: 10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 645 ms, sys: 54.1 ms, total: 699 ms\n",
      "Wall time: 7min 38s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "function = functools.partial(worker, strDataBucketName) # 반복되는 것은 먼저 쓰기 \n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=20) as executor:\n",
    "    #res = list(executor.map(function, [nIdx for nIdx in range(nModels)]))\n",
    "    res = list(executor.map(function, [(nIdx, nSpare+1) for (nIdx, nSpare) in zip(range(nModels), range(nModels))]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
